import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torchvision.models as models
from torchvision import transforms
import os
from collections import Counter

def main():
    device = torch.device("cpu")
    if torch.cuda.is_available():
        device = torch.device("cuda")
    elif torch.backends.mps.is_built() and torch.backends.mps.is_available():
        device = torch.device("mps")
    print(device)

    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    TRAIN_COUNTRIES_DIR = os.path.join(BASE_DIR, "trainEurope")
    TEST_COUNTRIES_DIR = os.path.join(BASE_DIR, "testEurope")

    weights = models.ResNet50_Weights.DEFAULT
    mean, std = weights.transforms().mean, weights.transforms().std

    train_transform = transforms.Compose([
        transforms.Resize(320),
        transforms.RandomResizedCrop(288, scale=(0.6, 1.0), ratio=(0.8, 1.25)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomApply([transforms.ColorJitter(0.35, 0.35, 0.35, 0.15)], p=0.8),
        transforms.RandomGrayscale(p=0.05),
        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.15),
        transforms.ToTensor(),
        transforms.Normalize(mean, std),
        transforms.RandomErasing(p=0.2, scale=(0.02, 0.15), ratio=(0.3, 3.3), value="random"),
    ])

    test_transform = transforms.Compose([
        transforms.Resize(320),
        transforms.CenterCrop(288),
        transforms.ToTensor(),
        transforms.Normalize(mean, std),
    ])

    train_dataset = ImageFolder(root=TRAIN_COUNTRIES_DIR, transform=train_transform)
    test_dataset = ImageFolder(root=TEST_COUNTRIES_DIR, transform=test_transform)

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=(device.type == "cuda"))
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=(device.type == "cuda"))

    num_classes = len(train_dataset.classes)

    net = models.resnet50(weights=weights)
    net.fc = nn.Sequential(
        nn.Dropout(0.3),
        nn.Linear(net.fc.in_features, num_classes)
    )
    net = net.to(device)

    counts = Counter(train_dataset.targets)
    class_weights = torch.tensor([1.0 / counts[i] for i in range(num_classes)], dtype=torch.float32).to(device)

    loss_function = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)

    for p in net.parameters():
        p.requires_grad = False
    for p in net.fc.parameters():
        p.requires_grad = True

    optimizer = optim.AdamW(net.fc.parameters(), lr=3e-4, weight_decay=1e-3)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)

    for epoch in range(5):
        net.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad(set_to_none=True)
            outputs = net(inputs)
            loss = loss_function(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)
            optimizer.step()
            running_loss += loss.item()
        scheduler.step()
        print(f"[{epoch+1}/25] loss: {running_loss/len(train_loader):.4f}")

    for p in net.layer4.parameters():
        p.requires_grad = True

    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()), lr=1e-4, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)

    for epoch in range(5, 25):
        net.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad(set_to_none=True)
            outputs = net(inputs)
            loss = loss_function(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)
            optimizer.step()
            running_loss += loss.item()
        scheduler.step()
        print(f"[{epoch+1}/25] loss: {running_loss/len(train_loader):.4f}")

    correct = 0
    total = 0
    net.eval()
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            predicted = outputs.argmax(dim=1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"Accuracy of the network: {100 * correct / total:.2f}%")

if __name__ == "__main__":
    main()
